{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8a0761",
   "metadata": {},
   "source": [
    "# üè† Rooftop Segmentation with DeepLabV3Plus\n",
    "\n",
    "This notebook contains everything needed for rooftop segmentation:\n",
    "- Data loading and preprocessing\n",
    "- Model training\n",
    "- Visualization and inference\n",
    "\n",
    "Run cells sequentially from top to bottom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64ab05",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d52a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:39:45.632443Z",
     "iopub.status.busy": "2025-11-15T15:39:45.630647Z",
     "iopub.status.idle": "2025-11-15T15:39:57.033420Z",
     "shell.execute_reply": "2025-11-15T15:39:57.032454Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import random\n",
    "from torchvision import transforms as tfs\n",
    "\n",
    "# Fix for Windows multiprocessing\n",
    "if sys.platform == 'win32':\n",
    "    import multiprocessing\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1285cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297e2e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:39:58.381742Z",
     "iopub.status.busy": "2025-11-15T15:39:58.380569Z",
     "iopub.status.idle": "2025-11-15T15:39:58.404963Z",
     "shell.execute_reply": "2025-11-15T15:39:58.402949Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSegmentationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, transformations=None):\n",
    "        all_images = sorted(glob(f\"{root}/images/images/*\"))\n",
    "        \n",
    "        pairs = []\n",
    "        for img_path in all_images:\n",
    "            label_path = f\"{root}/label/label/{self.get_filename(img_path)}_label.tif\"\n",
    "            if os.path.exists(label_path):\n",
    "                pairs.append((img_path, label_path))\n",
    "        \n",
    "        self.image_paths = [p[0] for p in pairs]\n",
    "        self.label_paths = [p[1] for p in pairs]\n",
    "        self.transformations = transformations\n",
    "        self.n_cls = 2\n",
    "        \n",
    "        assert len(self.image_paths) == len(self.label_paths)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.load_image_pair(self.image_paths[idx], self.label_paths[idx])\n",
    "        \n",
    "        if self.transformations:\n",
    "            transformed = self.transformations(image=img, mask=label)\n",
    "            img = transformed[\"image\"]\n",
    "            label = transformed[\"mask\"]\n",
    "        \n",
    "        return img, (label / 255).int()\n",
    "        \n",
    "    def get_filename(self, path):\n",
    "        return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    def load_image_pair(self, img_path, label_path):\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        label = np.array(Image.open(label_path).convert(\"L\"))\n",
    "        return img, label\n",
    "\n",
    "def get_dataloaders(root, transformations, batch_size, split=[0.9, 0.05, 0.05], num_workers=0):\n",
    "    assert abs(sum(split) - 1.0) < 0.001, \"Split ratios must sum to 1\"\n",
    "    \n",
    "    dataset = CustomSegmentationDataset(root=root, transformations=transformations)\n",
    "    n_classes = dataset.n_cls\n",
    "    \n",
    "    total = len(dataset)\n",
    "    \n",
    "    if total == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  WARNING: No images found in dataset!\")\n",
    "        print(f\"   Please check:\")\n",
    "        print(f\"   1. Dataset directory exists: {root}/\")\n",
    "        print(f\"   2. Images are in: {root}/images/images/\")\n",
    "        print(f\"   3. Labels are in: {root}/label/label/\")\n",
    "        print(f\"   4. Label naming: {{image_name}}_label.tif\")\n",
    "        print(f\"\\n   Please check your dataset structure matches the requirements.\\n\")\n",
    "        raise ValueError(f\"No images found in dataset directory: {root}\")\n",
    "    \n",
    "    train_size = int(total * split[0])\n",
    "    val_size = int(total * split[1])\n",
    "    test_size = total - train_size - val_size\n",
    "    \n",
    "    # Ensure at least 1 sample in each split if possible\n",
    "    if total >= 3:\n",
    "        if train_size == 0:\n",
    "            train_size = 1\n",
    "        if val_size == 0:\n",
    "            val_size = 1\n",
    "        if test_size == 0:\n",
    "            test_size = total - train_size - val_size\n",
    "    \n",
    "    train_ds, val_ds, test_ds = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Train set: {len(train_ds)} images\")\n",
    "    print(f\"Validation set: {len(val_ds)} images\")\n",
    "    print(f\"Test set: {len(test_ds)} images\\n\")\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_dl, val_dl, test_dl, n_classes\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3819ff8",
   "metadata": {},
   "source": [
    "## 5. Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d1fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:39:58.410366Z",
     "iopub.status.busy": "2025-11-15T15:39:58.410366Z",
     "iopub.status.idle": "2025-11-15T15:39:58.562022Z",
     "shell.execute_reply": "2025-11-15T15:39:58.560258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "root = \"dataset\"\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "img_size = 256\n",
    "batch_size = 32\n",
    "\n",
    "# Check if dataset directory exists\n",
    "if not os.path.exists(root):\n",
    "    print(f\"‚ö†Ô∏è  Dataset directory '{root}' not found!\")\n",
    "    print(f\"   Current working directory: {os.getcwd()}\")\n",
    "    print(f\"   Please ensure the dataset folder exists.\\n\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset directory found: {os.path.abspath(root)}\")\n",
    "\n",
    "# Data transformations\n",
    "transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    A.Normalize(mean=mean, std=std),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "# Use num_workers=0 on Windows to avoid multiprocessing issues\n",
    "num_workers = 0 if sys.platform == 'win32' else 2\n",
    "\n",
    "# Load data\n",
    "tr_dl, val_dl, test_dl, n_cls = get_dataloaders(\n",
    "    root=root, \n",
    "    transformations=transform, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6286f0",
   "metadata": {},
   "source": [
    "## 7. Model Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288d8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:40:02.245286Z",
     "iopub.status.busy": "2025-11-15T15:40:02.244011Z",
     "iopub.status.idle": "2025-11-15T15:40:02.786559Z",
     "shell.execute_reply": "2025-11-15T15:40:02.785541Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create model\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=n_cls,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: DeepLabV3Plus with ResNet50 encoder\")\n",
    "print(f\"   Classes: {n_cls}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b003e",
   "metadata": {},
   "source": [
    "## 8. Loss Function and Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07de72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:40:02.791643Z",
     "iopub.status.busy": "2025-11-15T15:40:02.790638Z",
     "iopub.status.idle": "2025-11-15T15:40:02.820771Z",
     "shell.execute_reply": "2025-11-15T15:40:02.819741Z"
    }
   },
   "outputs": [],
   "source": [
    "class CombinedLoss(torch.nn.Module):\n",
    "    def __init__(self, ce_weight=0.6, dice_weight=0.4, n_cls=2):\n",
    "        super().__init__()\n",
    "        self.ce = torch.nn.CrossEntropyLoss()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.n_cls = n_cls\n",
    "        \n",
    "    def dice(self, pred, target):\n",
    "        smooth = 1.0\n",
    "        pred_soft = F.softmax(pred, dim=1)\n",
    "        pred_hot = F.one_hot(torch.argmax(pred_soft, dim=1), self.n_cls).permute(0, 3, 1, 2).float()\n",
    "        target_hot = F.one_hot(target.squeeze(1).long(), self.n_cls).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        inter = (pred_hot * target_hot).sum(dim=(2, 3))\n",
    "        union = pred_hot.sum(dim=(2, 3)) + target_hot.sum(dim=(2, 3))\n",
    "        dice_score = (2.0 * inter + smooth) / (union + smooth)\n",
    "        return 1 - dice_score.mean()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = self.ce(pred, target.squeeze(1).long())\n",
    "        dice_loss = self.dice(pred, target)\n",
    "        return self.ce_weight * ce_loss + self.dice_weight * dice_loss\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, pred, gt, loss_fn, eps=1e-10, n_cls=2):\n",
    "        self.pred = torch.argmax(pred, dim=1)\n",
    "        self.gt = gt.squeeze(1)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.eps = eps\n",
    "        self.n_cls = n_cls\n",
    "        self.pred_full = pred\n",
    "        \n",
    "    def to_flat(self, x):\n",
    "        return x.contiguous().view(-1)\n",
    "    \n",
    "    def pixel_accuracy(self):\n",
    "        with torch.no_grad():\n",
    "            correct = torch.eq(self.pred, self.gt).int()\n",
    "        return float(correct.sum()) / float(correct.numel())\n",
    "\n",
    "    def mean_iou(self):\n",
    "        with torch.no_grad():\n",
    "            pred_flat = self.to_flat(self.pred)\n",
    "            gt_flat = self.to_flat(self.gt)\n",
    "            \n",
    "            ious = []\n",
    "            for cls in range(self.n_cls):\n",
    "                pred_cls = pred_flat == cls\n",
    "                gt_cls = gt_flat == cls\n",
    "                \n",
    "                if gt_cls.long().sum().item() == 0:\n",
    "                    ious.append(np.nan)\n",
    "                else:\n",
    "                    inter = torch.logical_and(pred_cls, gt_cls).sum().float().item()\n",
    "                    union = torch.logical_or(pred_cls, gt_cls).sum().float().item()\n",
    "                    iou = (inter + self.eps) / (union + self.eps)\n",
    "                    ious.append(iou)\n",
    "                    \n",
    "            return np.nanmean(ious)\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        return self.loss_fn(self.pred_full, self.gt.long())\n",
    "\n",
    "def timer(start=None):\n",
    "    if start is None:\n",
    "        return time.time()\n",
    "    return time.time() - start\n",
    "\n",
    "# Initialize loss function\n",
    "loss_fn = CombinedLoss(ce_weight=0.6, dice_weight=0.4, n_cls=n_cls)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"‚úÖ Loss function, optimizer, and scheduler initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3563b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14054d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:40:02.826377Z",
     "iopub.status.busy": "2025-11-15T15:40:02.826377Z",
     "iopub.status.idle": "2025-11-15T15:40:02.844914Z",
     "shell.execute_reply": "2025-11-15T15:40:02.844447Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, scaler, device, epochs, save_prefix, n_cls, threshold=0.005, save_path=\"saved_models\", grad_clip=1.0):\n",
    "    train_losses, train_pa, train_iou = [], [], []\n",
    "    val_losses, val_pa, val_iou = [], [], []\n",
    "    train_batches = len(train_loader)\n",
    "    val_batches = len(val_loader)\n",
    "    best_iou = 0.0\n",
    "    best_loss = float('inf')\n",
    "    no_improve = 0\n",
    "    early_stop = 10\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        print(f\"Model on GPU: {next(model.parameters()).is_cuda}\")\n",
    "    \n",
    "    start_time = timer()\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = timer()\n",
    "        train_loss, train_iou_val, train_pa_val = 0, 0, 0\n",
    "        \n",
    "        model.train()\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Training\"):\n",
    "            images, masks = batch\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                predictions = model(images)\n",
    "                metrics = Metrics(predictions, masks, loss_fn, n_cls=n_cls)\n",
    "                loss = metrics.compute_loss()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_iou_val += metrics.mean_iou()\n",
    "                train_pa_val += metrics.pixel_accuracy()\n",
    "                train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_iou_val, val_pa_val = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validation\"):\n",
    "                images, masks = batch\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                \n",
    "                with autocast():\n",
    "                    predictions = model(images)\n",
    "                    metrics = Metrics(predictions, masks, loss_fn, n_cls=n_cls)\n",
    "                \n",
    "                val_loss += metrics.compute_loss().item()\n",
    "                val_iou_val += metrics.mean_iou()\n",
    "                val_pa_val += metrics.pixel_accuracy()\n",
    "        \n",
    "        train_loss /= train_batches\n",
    "        train_iou_val /= train_batches\n",
    "        train_pa_val /= train_batches\n",
    "        \n",
    "        val_loss /= val_batches\n",
    "        val_iou_val /= val_batches\n",
    "        val_pa_val /= val_batches\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch} Results:\")\n",
    "        print(f\"Time: {timer(epoch_start):.2f}s | LR: {current_lr:.6f}\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, PA: {train_pa_val:.4f}, IoU: {train_iou_val:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, PA: {val_pa_val:.4f}, IoU: {val_iou_val:.4f}\\n\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_iou.append(train_iou_val)\n",
    "        train_pa.append(train_pa_val)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_iou.append(val_iou_val)\n",
    "        val_pa.append(val_pa_val)\n",
    "        \n",
    "        improved = False\n",
    "        if val_iou_val > best_iou:\n",
    "            print(f\"IoU improved: {best_iou:.4f} -> {val_iou_val:.4f}\")\n",
    "            best_iou = val_iou_val\n",
    "            improved = True\n",
    "            no_improve = 0\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_iou': best_iou,\n",
    "                'val_loss': val_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_path}/{save_prefix}_best_model_iou.pt\")\n",
    "            print(f\"Saved model (IoU: {best_iou:.4f})\\n\")\n",
    "        \n",
    "        if val_loss < best_loss - threshold:\n",
    "            print(f\"Loss improved: {best_loss:.4f} -> {val_loss:.4f}\")\n",
    "            best_loss = val_loss\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_loss': best_loss,\n",
    "                'val_iou': val_iou_val,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_path}/{save_prefix}_best_model_loss.pt\")\n",
    "            print(f\"Saved model (Loss: {best_loss:.4f})\\n\")\n",
    "        \n",
    "        if not improved:\n",
    "            no_improve += 1\n",
    "            print(f\"No improvement for {no_improve} epochs\")\n",
    "            if no_improve >= early_stop:\n",
    "                print(f\"\\nEarly stopping after {no_improve} epochs\\n\")\n",
    "                break\n",
    "    \n",
    "    total_time = timer(start_time) / 60\n",
    "    print(f\"\\nTraining completed in {total_time:.2f} minutes\")\n",
    "    print(f\"Best IoU: {best_iou:.4f} | Best Loss: {best_loss:.4f}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"tr_loss\": train_losses, \"tr_iou\": train_iou, \"tr_pa\": train_pa,\n",
    "        \"val_loss\": val_losses, \"val_iou\": val_iou, \"val_pa\": val_pa,\n",
    "        \"best_iou\": best_iou, \"best_loss\": best_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20118f52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e56696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T15:40:02.847970Z",
     "iopub.status.busy": "2025-11-15T15:40:02.847970Z",
     "iopub.status.idle": "2025-11-15T16:03:00.535737Z",
     "shell.execute_reply": "2025-11-15T16:03:00.534835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify dataloaders have data before training\n",
    "if len(tr_dl) == 0:\n",
    "    raise ValueError(\"Training dataloader is empty! Please check your dataset.\")\n",
    "if len(val_dl) == 0:\n",
    "    raise ValueError(\"Validation dataloader is empty! Please check your dataset.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Ready to train!\")\n",
    "print(f\"   Training batches: {len(tr_dl)}\")\n",
    "print(f\"   Validation batches: {len(val_dl)}\")\n",
    "print(f\"   Test batches: {len(test_dl)}\")\n",
    "print(f\"   Model: DeepLabV3Plus with ResNet50 encoder\")\n",
    "print(f\"   Classes: {n_cls}\")\n",
    "print(f\"   Epochs: 50\\n\")\n",
    "\n",
    "# Start training\n",
    "history = train(\n",
    "    model=model,\n",
    "    train_loader=tr_dl,\n",
    "    val_loader=val_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    save_prefix=\"rooftop\",\n",
    "    n_cls=n_cls,\n",
    "    grad_clip=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2dbcc",
   "metadata": {},
   "source": [
    "## 11. Visualize Learning Curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5ed72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:03:00.540315Z",
     "iopub.status.busy": "2025-11-15T16:03:00.540315Z",
     "iopub.status.idle": "2025-11-15T16:03:01.216425Z",
     "shell.execute_reply": "2025-11-15T16:03:01.214445Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearningCurves:\n",
    "    def __init__(self, results):\n",
    "        self.results = results\n",
    "        self.plot_curve(\"tr_iou\", \"val_iou\", \"Train IoU\", \"Val IoU\", \"IoU\", \"IoU Score\")\n",
    "        self.plot_curve(\"tr_pa\", \"val_pa\", \"Train PA\", \"Val PA\", \"Pixel Accuracy\", \"PA Score\")\n",
    "        self.plot_curve(\"tr_loss\", \"val_loss\", \"Train Loss\", \"Val Loss\", \"Loss\", \"Loss Value\")\n",
    "    \n",
    "    def plot_curve(self, train_key, val_key, train_label, val_label, title, ylabel):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.results[train_key], label=train_label)\n",
    "        plt.plot(self.results[val_key], label=val_label)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Plot learning curves\n",
    "if 'history' in locals():\n",
    "    LearningCurves(history)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training history found. Please train the model first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742433b",
   "metadata": {},
   "source": [
    "## 12. Inference on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816833a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:03:01.223921Z",
     "iopub.status.busy": "2025-11-15T16:03:01.222786Z",
     "iopub.status.idle": "2025-11-15T16:03:02.890937Z",
     "shell.execute_reply": "2025-11-15T16:03:02.889926Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference(data_loader, model, device, num_images=15):\n",
    "    cols = num_images // 3\n",
    "    rows = num_images // cols\n",
    "    \n",
    "    images_list, masks_list, predictions_list = [], [], []\n",
    "    \n",
    "    for data in data_loader:\n",
    "        img, mask = data\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(model(img.to(device)), dim=1)\n",
    "        images_list.append(img)\n",
    "        masks_list.append(mask)\n",
    "        predictions_list.append(pred)\n",
    "    \n",
    "    plt.figure(figsize=(25, 20))\n",
    "    pos = 1\n",
    "    \n",
    "    for i, (img, mask, pred) in enumerate(zip(images_list, masks_list, predictions_list)):\n",
    "        if i >= cols:\n",
    "            break\n",
    "        \n",
    "        pos = plot_image(cols, rows, pos, img, title=\"Original\")\n",
    "        pos = plot_image(cols, rows, pos, mask.squeeze(0), is_mask=True, title=\"Ground Truth\")\n",
    "        pos = plot_image(cols, rows, pos, pred, is_mask=True, title=\"Prediction\")\n",
    "\n",
    "# Load best model\n",
    "iou_path = \"saved_models/rooftop_best_model_iou.pt\"\n",
    "loss_path = \"saved_models/rooftop_best_model_loss.pt\"\n",
    "old_path = \"saved_models/rooftop_best_model.pt\"\n",
    "\n",
    "if os.path.exists(iou_path):\n",
    "    print(f\"Loading model from {iou_path}\")\n",
    "    checkpoint = torch.load(iou_path, map_location=device)\n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Best IoU: {checkpoint.get('best_iou', 'N/A')}\")\n",
    "    else:\n",
    "        model = checkpoint\n",
    "elif os.path.exists(loss_path):\n",
    "    print(f\"Loading model from {loss_path}\")\n",
    "    checkpoint = torch.load(loss_path, map_location=device)\n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Best Loss: {checkpoint.get('best_loss', 'N/A')}\")\n",
    "    else:\n",
    "        model = checkpoint\n",
    "elif os.path.exists(old_path):\n",
    "    print(f\"Loading model from {old_path}\")\n",
    "    model = torch.load(old_path, map_location=device)\n",
    "else:\n",
    "    raise FileNotFoundError(\"No model found! Train the model first.\")\n",
    "        \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Run inference\n",
    "if len(test_dl) > 0:\n",
    "    run_inference(test_dl, model, device)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test dataloader is empty. Cannot run inference.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}